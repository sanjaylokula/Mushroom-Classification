---
title: "Mushroom Classification"
author: "Sanjay Lokula"
date: "24/06/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Loading the Necessary Libraries

```{r}
library(stringr)
library(stringi)
library(car)
library(dplyr)
library(ggplot2)
library(dplyr)
library(corrplot)
library(Seurat)
library(caret)
library(plyr)
library(data.table)
library(randomForest)
library(gbm)
library(Metrics)
library(regclass)

```


#### Loading the Dataset

```{r}
mushroom_data <- read.csv(file.choose(), stringsAsFactors = FALSE)
```


#### Summary of the dataset

```{r}
summary(mushroom_data)
```

```{r}
View(mushroom_data)
```

#### Class identification

```{r}
str(mushroom_data)
# All type of data are factor

```


#### Missing value analysis
# Let's see is there any NA value and is there any column needs a better name
```{r}
sapply(mushroom_data,function(x)sum(is.na(x)))
# There is no missing value in any column, and all column's name are clear

```

### EDA (Exploratory Data Analysis)

#### Feature Analysis

```{r}

class <- plyr::count(mushroom_data$class)
print(sprintf("Edible: %d | Poisonous: %d | Percent of poisonous classes: %.1f%%",class$freq[1],class$freq[2], round(class$freq[1]/nrow(mushroom_data)*100,1)))
```


#### Analyzing the attributes with low numbers of categories
#### Analyzing "bruises"

```{r}
ggplot(mushroom_data, aes(bruises, fill = class)) + geom_bar(position = "dodge")
```

#### Analyzing gill.attachment
```{r}
ggplot(mushroom_data, aes(gill.attachment, fill = class)) + geom_bar(position = "dodge")

```



#### gill.spacing
```{r}
ggplot(mushroom_data, aes(gill.spacing, fill = class)) + geom_bar(position = "dodge")

```


#### Almost equally distributed classes 

#### gill.size
```{r}
ggplot(mushroom_data, aes(gill.size, fill = class)) + geom_bar(position = "dodge")

```



#### stalk.shape
```{r}
ggplot(mushroom_data, aes(stalk.shape, fill = class)) + geom_bar(position = "dodge")

```


#### odor
```{r}
ggplot(mushroom_data, aes(odor, fill = class)) + geom_bar(position = "dodge")
#Fully Edible: 'a' & 'l'
#Mostly Edible: 'n' (A very small portion of this class fall under poisonous)
#Fully poisonous: 'c', 'f', 'm','p', 's' & 'y'
```




#### Class analysis
##### Calculate number of class for each variable
```{r}
num_of_class <-cbind.data.frame(Var=names(mushroom_data), Total_Class=sapply(mushroom_data,function(x){as.numeric(length(levels(factor(x))))}))
num_of_class

```

### Features analysis Part 2
#### In case if needs to do further investigate so transfter all factor to numeric

```{r}
mushroom_numeric<- sapply(mushroom_data[,1:23], function (x) as.numeric(as.factor(x)))
head(mushroom_numeric)
```




### Correlation analysis
#####  Delete no.17 column of veil-type since it has only one type that is partial
```{r}
cor_mushroom <- cor(mushroom_numeric[, -17])
corrplot.mixed(cor_mushroom,order="AOE")


CombinePlots(plots=list(a,b,c,d,e,f))
a= ggplot(mushroom_data) + geom_bar(aes(x = class))+
  ggtitle("Distribution of class") + ylim(0, 5000)

b = ggplot(mushroom_data) + geom_bar(aes(x = cap.shape))+
  ggtitle("Distribution of cap.shape") + ylim(0, 4000)

c = ggplot(mushroom_data) + geom_bar(aes(x = cap.surface))+
  ggtitle("Distribution of cap.surface") + ylim(0, 4000)

d = ggplot(mushroom_data) + geom_bar(aes(x = cap.color))+
  ggtitle("Distribution of cap.color") + ylim(0, 3000)

e = ggplot(mushroom_data) + geom_bar(aes(x = bruises))+
  ggtitle("Distribution of bruises") + ylim(0, 5000)

f = ggplot(mushroom_data) + geom_bar(aes(x = odor))+
  ggtitle("Distribution of odor") + ylim(0, 4000)

```

### Data Preprocessing

#### Removing veil.type as it has only one factor
#### Converting all the columns to factors 

```{r}
mushroom_data_mod1 <- mushroom_data %>% select(-veil.type)
mushroom_data_mod1[names(mushroom_data_mod1)] <- lapply(mushroom_data_mod1[names(mushroom_data_mod1)], as.factor)
```


#### As the response is a dicotomous value performing logistic regression to check the variable importance

```{r}
model_logistic_test <-  glm(class ~. , data = mushroom_data_mod1, family = binomial(link = logit))
summary(model_logistic_test)
```
#### Identified 10 variables with un-defined coefficients due to singularities.

#### Applying vif
```{r}
vif(model_logistic_test)
```

#### Due to the presence of singularities unable to do VIF
#### Applying alias to identify and remove singularities

```{r}
aliases_round1 <- alias(model_logistic_test)
excluded_factors_round1<- rownames(aliases_round1$Complete)
print(excluded_factors_round1)
```

#### Removing factors show singularities

```{r}

fact_round0 <- model.matrix(~. , mushroom_data_mod1)[,-1]

factors_round1 <- setdiff(colnames(fact_round0), excluded_factors_round1)

mushroom_data_mod2 <- as.data.frame(fact_round0[,factors_round1])
colnames(mushroom_data_mod2)
```
#### Round 2 verification for singularities

```{r}
model_logistic_test2 <-  glm(classp ~. , data = mushroom_data_mod2, family = binomial(link = logit))
summary(model_logistic_test2)
```
#### model summary shows no singularities

#### proceeding with VIF analysis

```{r}
vif_round1 <- vif(model_logistic_test2)
```

#### Multiple factos show VIF greater than 10, Benchmark set to 10

```{r}
vif_df_round1 <- as.data.frame(vif_round1)
setDT(vif_df_round1, keep.rownames = TRUE)[]
vif_rn1_exclude <- filter(vif_df_round1, vif_round1 > 10)[,1]

```
#### Excluded highly correlated factors Round 1

```{r}
vif_fact_round0 <- model.matrix(~. , mushroom_data_mod2)[,-1]

factors_round1 <- setdiff(colnames(vif_fact_round0), vif_rn1_exclude)

mushroom_data_mod3 <- as.data.frame(vif_fact_round0[,factors_round1])
colnames(mushroom_data_mod3)
```

### Round 2 Vif Analysis
```{r}
model_logistic_test3 <- glm(classp ~. , data = mushroom_data_mod3, family = binomial(link = logit))

vif_df_round2 <- as.data.frame(vif(model_logistic_test3))
# renaming the first column back to value
setDT(vif_df_round2, keep.rownames = TRUE)[]
# renaming the second column back to value

names(vif_df_round2)[2] <- "value"
vif_rn2_exclude <- filter(vif_df_round2, value > 10)[,1]
print(vif_rn2_exclude)
```

### Still there are a few variables with vif value greater than 10
#### eliminating 2 factos

#### Excluded highly correlated factors Round 2

```{r}
vif_fact_round1 <- model.matrix(~. , mushroom_data_mod3)[,-1]

factors_round1 <- setdiff(colnames(vif_fact_round1), vif_rn2_exclude)

mushroom_data_mod4 <- as.data.frame(vif_fact_round0[,factors_round1])
colnames(mushroom_data_mod3)
```

### Backward feature selection using step selection

```{r}
model_logistic_test4 <- glm(classp ~. , data = mushroom_data_mod2, family = binomial(link = logit))
stepModel <- step(model_logistic_test4, direction = "forward")
```

```{r}
summary(stepModel)
```
```{r}
# Splitting the data into train and test, train=80% and test=20%
split_data <- sample(1:nrow(mushroom_data_mod4), size=0.8*nrow(mushroom_data_mod4))
trainset = data.frame(mushroom_data_mod4[split_data ,])
testset = data.frame(mushroom_data_mod4[-split_data ,])

```

```{r}
## Modeling

## Logistic regression

# use all the variables first 
model_logistic <- glm(classp ~. , data = trainset, family = binomial(link = logit))
# Summary of the primary model
summary(model_logistic) 

# Predict and Test data
predictions <- as.data.frame(predict(model_logistic,testset[,-1],type = "response"))
# renaming the column names
names(predictions) <- c("predicted")
class(predictions)
# The threshold value used is 0.5
predictions <- predictions %>% mutate(predicted = as.numeric((as.numeric(predicted) > as.numeric(0.6))))

# Actual Data
Actual <- as.data.frame(testset[,1])
names(Actual) <- c("original")


# Confusion Matrix is developed to find the accuracy of the model
confusionMatrix(factor(predictions$predicted), factor(Actual$original))
```
```{r}
## Random forest model

set.seed(4543)
model_rf <- randomForest(
  factor(classp) ~ .,
  data = trainset, ntree =100, importance =T
)

# predictions
predictions_rf <-  as.data.frame(predict(model_rf,testset[,-1],type = "response"))
colnames(predictions_rf) <- c("prediction_1")

# Calculating the model accuracy
summary(model_rf)
confusionMatrix(factor(predictions_rf$prediction_1), factor(testset$class))


# Calculating AUC  -- Area under the curve

print(sprintf("Area under curve (AUC) : %.3f",auc(testset$classp, predictions_rf$prediction_1)))

```
```{r}
varImpPlot(model_rf, n.var=min(15, nrow(model_rf$importance)))
```

```{r}
varimp <- data.frame(model_rf$importance)
  vi1 <- ggplot(varimp, aes(x=reorder(rownames(varimp),IncNodePurity), y=IncNodePurity)) +
  geom_bar(stat="identity", fill="green", colour="black") +
  coord_flip() + theme_bw(base_size = 8) +
  labs(title="Prediction using RandomForest with 100 trees", subtitle="Variable importance (IncNodePurity)", x="Variable", y="Variable importance (IncNodePurity)")
  vi2 <- ggplot(varimp, aes(x=reorder(rownames(varimp),X.IncMSE), y=X.IncMSE)) +
  geom_bar(stat="identity", fill="lightblue", colour="black") +
  coord_flip() + theme_bw(base_size = 8) +
  labs(title="Prediction using RandomForest with 100 trees", subtitle="Variable importance (%IncMSE)", x="Variable", y="Variable importance (%IncMSE)")
  grid.arrange(vi1, vi2, ncol=2)
```

```{r}
summarize_tree(model_rf)
```


```{r}
## Gradient Boost Machine (GBM) model

# names of the dataset
n<-names(trainset)
# calculating the form using regex modeling class with all the variables except class
gbm.form <- as.formula(paste("classp ~", paste(n[!n %in% "classp"], collapse = " + ")))
# modeling the gbm using n.trees=400, shrinkage =0.01 and 10 fold cross validation
model_gbm = gbm(formula = gbm.form,
            distribution = "bernoulli",
            data = trainset,
            n.trees = 400,
            shrinkage = .2,
            n.minobsinnode = 15,
            cv.folds = 10,
            n.cores = 1)
# Calulating the optimal trees value using the gbm.performance
optimaltrees = gbm.perf(model_gbm)



# predicting on the test dataset
predicted_gbm = as.data.frame(predict(object = model_gbm,
                  newdata = testset[,-1],
                  n.trees = optimaltrees,
                  type = "response"))
# Changing the column name
colnames(predicted_gbm) <- c("prediction_1")
# The threshold value used is 0.5
predictions_gbm <- predicted_gbm %>% mutate(prediction_1 = as.numeric((as.numeric(prediction_1) > as.numeric(0.5))))

# plotting the confusion matrix
confusionMatrix(factor(predictions_gbm$prediction_1), factor(testset$class))
print(sprintf("Area under curve (AUC) : %.3f",auc(testset$class, predictions_gbm$prediction_1)))

```

